# Jigsaw Unintended Bias in Toxicity Classification

- Overview
- Dataset
- Data Description
- Project Goal
- Architecture
- Implementation Details
- Results
- Repository Files
- Blog
- References / Useful Resources

## Overview
The invention of the World Wide Web connected the world in a way that was not possible before. It made much easier for people to get information, share and communicate. It allowed people to share their work and thoughts through social networking sites, blogs, video sharing, etc.

But while the internet and its offshoot technologies have improved society and daily life in many ways, they have also been an unmitigated disaster for the way people communicate online. It has become increasingly common for people to participate in online bullying, abuse and spreading hate. While freedom of speech is important, creating an inclusive platform for meaningful discussion is also necessary.

This is a implementation of one such system that can accomplish the task of tackling the menace of online bullying, and hate.

## Dataset
The dataset is taken from a competition hosted on Kaggle by The Conversation AI team (research initiated by Jigsaw and Google).

Source: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data

## Data Description


## Project Goal

The goal of the project is to build a model that can classify the toxicity\* of a comment, ie we have to predict if a comment is toxic or non-toxic.

* \* Toxic comments are the comments which are offensive and sometimes can make some people leave the discussion (on public forums) *

## Architecture

## Implementation Details

## Results

## Directory Tree Structure

## Blog
An article about this project: https://medium.com/swlh/jigsaw-unintended-bias-in-toxicity-classification-a-kaggle-case-study-f47938753347

## References / Useful Resources
