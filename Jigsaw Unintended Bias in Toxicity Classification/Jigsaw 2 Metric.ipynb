{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2 Metric.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPjPRaV0deZnTTIfsweJcmu"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gLgoxaENgSqV","colab_type":"text"},"source":["# Evaluation\n"]},{"cell_type":"markdown","metadata":{"id":"Ef9qb5LNgVTk","colab_type":"text"},"source":["The problem uses a newly developed metric that combines several submetrics to balance overall performance with various aspects of unintended bias.\n","\n","The submetrics are:\n","\n","\n","**1.   Overall AUC:** This is the ROC-AUC for the full evaluation set.\n","\n","**2.   Bias AUCs:** To measure unintended bias, we again calculate the ROC-AUC on three specific subsets of the test set for each identity, each capturing a different aspect of unintended bias.\n","\n","\n","*   *a) Subgroup AUC:* Here, we restrict the data set to only the examples that mention the specific identity subgroup. A low value in this metric means the model does a poor job of distinguishing between toxic and non-toxic comments that mention the identity.\n","\n","*   *b) BPSN (Background Positive, Subgroup Negative) AUC:* Here, we restrict the test set to the non-toxic examples that mention the identity and the toxic examples that do not. A low value in this metric means that the model confuses non-toxic examples that mention the identity with toxic examples that do not, likely meaning that the model predicts higher toxicity scores than it should for non-toxic examples mentioning the identity.\n","\n","*   *c) BNSP (Background Negative, Subgroup Positive) AUC:* Here, we restrict the test set to the toxic examples that mention the identity and the non-toxic examples that do not. A low value here means that the model confuses toxic examples that mention the identity with non-toxic examples that do not, likely meaning that the model predicts lower toxicity scores than it should for toxic examples mentioning the identity.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-u1PkFy6mCfa","colab_type":"text"},"source":["Basically, the final score is an average of 4 AUC. And as such, we will use a custom loss function instead of just using the binary cross entropy."]},{"cell_type":"markdown","metadata":{"id":"S2pFj_R3m_jD","colab_type":"text"},"source":["# Loss Function"]},{"cell_type":"markdown","metadata":{"id":"IOkGvgsGnF7h","colab_type":"text"},"source":["There are 2 main changes of the loss fuction:"]},{"cell_type":"markdown","metadata":{"id":"sUkpzJYCoN_N","colab_type":"text"},"source":["__1. weight each sample:__\n","\n","The main idea is:\n","\n","Each sample participates in some of these AUC. __A sample that participates in 3 AUCs is more important than a sample that participates in 2 AUCs__ since giving a bad score to that sample affects the overall score more.\n","\n","So, We calculate the weight of each sample based on how many AUCs they belong to.\n"]},{"cell_type":"code","metadata":{"id":"yk7Gvy9To1Bf","colab_type":"code","colab":{}},"source":["# Overall\n","weights = np.ones((len(train_df),)) / 4\n","\n","# Subgroup\n","weights += (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) / 4\n","\n","# Background Positive, Subgroup Negative\n","weights += (( (train_df['target'].values>=0.5).astype(bool).astype(np.int) +\n","   (train_df[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n","\n","# Background Negative, Subgroup Positive\n","weights += (( (train_df['target'].values<0.5).astype(bool).astype(np.int) +\n","   (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) / 4\n","\n","# for later normalization the loss\n","loss_weight = 1.0 / weights.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pafIq67q0x49","colab_type":"code","colab":{}},"source":["y_train = np.vstack([train_df['target'], weights]).T"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUN3mheXpAQl","colab_type":"text"},"source":["__2. Auxiliary Target:__\n","\n","Because, the data also has several additional toxicity subtype attributes (severe_toxicity, obscene, threat, insult, identity_attack, sexual_explicit) that are highly correlated to the target, we also use the toxicity probabilities of these auxiliary targets."]},{"cell_type":"code","metadata":{"id":"Q7jQTYOX0kNv","colab_type":"code","colab":{}},"source":["y_aux_train = train_data[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TPm6iX8GuStl","colab_type":"text"},"source":["__The Loss Function:__"]},{"cell_type":"markdown","metadata":{"id":"9zBc4xYg1wyd","colab_type":"text"},"source":["- We will use a custom loss function to calculate loss for `y_train` outputs."]},{"cell_type":"code","metadata":{"id":"d9gDJ2ng0g8J","colab_type":"code","colab":{}},"source":["def custom_loss(y_true, y_pred):\n","    return binary_crossentropy(K.reshape(y_true[:,0],(-1,1)), y_pred) * y_true[:,1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4lOoVMW2Lik","colab_type":"text"},"source":["- `y_aux_train` losses will be calculated using usual 'binary_crossentropy'"]},{"cell_type":"markdown","metadata":{"id":"wXSz98Kr2jPc","colab_type":"text"},"source":["The overall loss will calculated will be as follows:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QkVSoXNR4G48","colab_type":"text"},"source":["<a href=\"https://www.codecogs.com/eqnedit.php?latex=finalLoss&space;=&space;(loss(yTtrain)&space;*&space;lossWeight)&space;&plus;&space;loss(yAuxTrain)\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?finalLoss&space;=&space;(loss(yTtrain)&space;*&space;lossWeight)&space;&plus;&space;loss(yAuxTrain)\" title=\"finalLoss = (loss(yTtrain) * lossWeight) + loss(yAuxTrain)\" /></a>"]}]}