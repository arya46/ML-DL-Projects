{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VQA 1 About Data.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMqqhAtjMdklm+CtNG2sYtM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fD5G2O14G-uO","colab_type":"text"},"source":["<h1> Visual Question Answering </h1>"]},{"cell_type":"markdown","metadata":{"id":"TX2dleWV6gje","colab_type":"text"},"source":["Visual Question Answering is a research area about building an AI system to answer questions presented in a natural language about an image.\n","\n","A system that solves this task demonstrates a more general understanding of images: it must be able to answer completely different questions about an image, oftentimes even addressing different sections of the image."]},{"cell_type":"markdown","metadata":{"id":"oCpdtr6Z_mlt","colab_type":"text"},"source":["Let's look at few examples: (Source: Original [VQA Paper](http://arxiv.org/pdf/1512.02167.pdf))"]},{"cell_type":"markdown","metadata":{"id":"IRDNpoSe8ThX","colab_type":"text"},"source":["![Example image](https://i.imgur.com/VH6DFNR.jpg)"]},{"cell_type":"markdown","metadata":{"id":"w1X2KKV4AFEE","colab_type":"text"},"source":["For all the images, our AI system should be able to localize the subject being referenced to in the question and detect it, and should have some common-sense knowledge to answer it.\n","\n","For instance, in the first image, and for the question \"What is the mustache made of ?\": our AI system should be able to figure out that the subject being referenced to is the women's face, more specifically the region around her lips, and should be able to detect the banana."]},{"cell_type":"markdown","metadata":{"id":"SGJtmtRuHDap","colab_type":"text"},"source":["# 1 About Data"]},{"cell_type":"markdown","metadata":{"id":"ZuDvABuj48GW","colab_type":"text"},"source":["VQA is a dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense knowledge to answer. \n","- 82,783 images (COCO)\n","- At least 3 questions (5.4 questions on average) per image (443,757 questions)\n","- 10 ground truth answers per question (443,7570 answers) from unique workers"]},{"cell_type":"markdown","metadata":{"id":"K78_L9z5HHz1","colab_type":"text"},"source":["<h2> 1.1 Business Problem </h2>"]},{"cell_type":"markdown","metadata":{"id":"ftqpl52awXRM","colab_type":"text"},"source":["\n","As humans, it is easy for us to see an image and answer any question about it using our commonsense knowledge. However, there are also scenerios, for instance, a visually-impaired user or an intelligence analysts, where they want to actively elicit visual information given an image. \n","\n","Hence, we build a AI system, which takes as input an image and a free-form, open-ended, or natural language question about the image and produces a natural language answer as the output.\n","\n","The system will answer a question similar to humans in the following aspects:  \n","1.   it will learn the visual and textual knowledge from the inputs (image and question respectively)\n","2.   combine the two data streams\n","3.   use this advanced knowledge to generate the answer"]},{"cell_type":"markdown","metadata":{"id":"TcovKV-6HK_A","colab_type":"text"},"source":["<h2> 1.2 Objective </h2>"]},{"cell_type":"markdown","metadata":{"id":"_90FAtiV-6Fg","colab_type":"text"},"source":["- Generate an answer to an open ended question about an image.\n","\n","*NB: We'll work with a fixed answer set where exactly one of the possible answers is guaranteed to be correct. This means we don't have to generate the answer, we just have to answer what is effectively a multiple-choice question. Most cutting-edge VQA systems out there have 1000 possible answers.*"]},{"cell_type":"markdown","metadata":{"id":"PdRYvYBE-edV","colab_type":"text"},"source":["<h2> 1.3 Constraints </h2>"]},{"cell_type":"markdown","metadata":{"id":"1T9C35_j-7us","colab_type":"text"},"source":["- No strict latency requirements."]},{"cell_type":"markdown","metadata":{"id":"nfN5lhe7-ssh","colab_type":"text"},"source":["# 2 Mapping the real-world problem to a ML problem"]},{"cell_type":"markdown","metadata":{"id":"Z7mI1fS2--sA","colab_type":"text"},"source":["<h2> 2.1 Type of Machine Learning Problem </h2>"]},{"cell_type":"markdown","metadata":{"id":"RLE3k3OyAplr","colab_type":"text"},"source":["We pose the problem at hand as a K-class classification problem; where K is the number of different types of answer in the dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"LqK_FXT1_2E3","colab_type":"text"},"source":["<h2>2.2 Performance Metric</h2>"]},{"cell_type":"markdown","metadata":{"id":"C_tra_hJAjek","colab_type":"text"},"source":["We evaluate our AI system by the number of questions it answers correctly.\n","\n","The following accuracy metric is used:\n","\n","$$accuracy = min({\\text{# humans that provided the predicted answer} \\over 3}, 1)$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NXTr4BIaAG_N","colab_type":"text"},"source":["<h2>2.3 Machine Learing Objectives and Constraints </h2>\n"]},{"cell_type":"markdown","metadata":{"id":"yBQVsWAMAgsy","colab_type":"text"},"source":["**Objective:**\n","- To generate an answer to an open ended question about an image. More specifically, we predict the class of the data-point as we have posed the problem as a K-class classification problem. \n","- Also, we try to maximize the final performance metric defined above. \n","\n","**Constraints:**\n","- There is no strict latency requirements."]}]}